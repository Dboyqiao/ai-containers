{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting Started with IntelÂ® oneCCL Bindings for PyTorch\n",
    "This code sample will guide users how to run a PyTorch DDP distributed workload on both GPU and CPU by using oneAPI AI Analytics Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple PyTorch distributed workload on both GPU and CPU\n",
    "***\n",
    "This section shows users how to run simple PyTorch distributed on both GPU and CPU with some code changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore all warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the installation path of your oneAPI AI Analytics toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ONEAPI_INSTALL=/opt/intel/oneapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a simple demo.py sample from torch-ccl github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/intel/torch-ccl/master/demo/demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check PyTorch and IPEX verson in current ipython kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simple PyTorch distributed DDP workload on GPU and CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run on CPU\n",
    "There is a **pytorch** conda environment with oneCCL Bindings installation for CPU in current AI Kit installation.  \n",
    "Users could run a PyTorch DDP workload on CPU in this conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run.sh\n",
    "#!/bin/bash\n",
    "source activate torch\n",
    "echo \"########## Executing the run\"\n",
    "mpirun -n 2 -l python demo.py --device cpu > cpu.csv\n",
    "echo \"########## Done with the run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submitting build.sh and run.sh to the job queue\n",
    "\n",
    "Now we can submit build.sh and run.sh to the job queue.\n",
    "\n",
    "NOTE - it is possible to execute any of the build and run commands in local environments.\n",
    "To enable users to run their scripts either on the Intel DevCloud or in local environments, this and subsequent training checks for the existence of the job submission command qsub. If the check fails, it is assumed that build/run will be local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run.sh; ./run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run on GPU \n",
    "There is a **pytorch-gpu** conda environment with oneCCL Bindings installation for GPU in current AI Kit installation.  \n",
    "Users could run a PyTorch DDP workload on GPU in this conda environment with one line code change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gpu.patch file under codes_for_ipynb contains the needed modifications to oneCCL Binding sample on GPU.\n",
    "We show the patch below, and users only need to make change device from cpu to xpu in their codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run.sh\n",
    "#!/bin/bash\n",
    "source activate pytorch\n",
    "echo \"########## Executing the run\"\n",
    "mpirun -n 2 -l python demo.py --device xpu > gpu.csv\n",
    "echo \"########## Done with the run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submitting build.sh and run.sh to the job queue\n",
    "\n",
    "Now we can submit build.sh and run.sh to the job queue.\n",
    "\n",
    "NOTE - it is possible to execute any of the build and run commands in local environments.\n",
    "To enable users to run their scripts either on the Intel DevCloud or in local environments, this and subsequent training checks for the existence of the job submission command qsub. If the check fails, it is assumed that build/run will be local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run.sh; ./run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CODE_SAMPLE_COMPLETED_SUCCESFULLY]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intel PyTorch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
